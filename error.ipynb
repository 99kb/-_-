{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비화재보 분류 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 데이터 전처리     \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 년도별 데이터 결합 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "import pickle\n",
    "import xlrd\n",
    "\n",
    "start_year= 2016\n",
    "end_year =2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n"
     ]
    }
   ],
   "source": [
    "df_all =pd.DataFrame()\n",
    "#년도합치기\n",
    "for year in range(start_year,end_year+1):\n",
    "#시트 이름 가져오기    \n",
    "    wb = xlrd.open_workbook(f\"{year}년 전체 신고건수_관할 및 재난주소 추가.xls\")\n",
    "    globals()[f'df_{year}']=pd.DataFrame()\n",
    "#Sheet 합치기\n",
    "    for  i in range(len(wb.sheets())):\n",
    "        tmp = pd.read_excel(f\"{year}년 전체 신고건수_관할 및 재난주소 추가.xls\",sheet_name = wb.sheet_names()[i])['신고내용'].dropna(axis=0).T\n",
    "        globals()[f'df_{year}']= pd.concat([globals()[f'df_{year}'],tmp], axis = 0)\n",
    "    df_all= pd.concat([df_all,globals()[f'df_{year}']], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 임시저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"119_신고내용_{start_year} - {end_year}.pickle\",\"wb\") as fw:\n",
    "#     pickle.dump(df_all, fw)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"119_신고내용_{start_year} - {end_year}.pickle\",'rb') as fr:\n",
    "    df_all = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 문자열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711724\n",
      "1368100\n",
      "                                  0\n",
      "0  [의식 있음] 내당홈플러스 3층 꽃집 앞 / 여성 쓰러짐 \n",
      "1        동구시장 풀과 나무 한의원//호흡곤란 사지 마비\n",
      "2                ★★주간 기동순찰 및 훈련출동★★\n"
     ]
    }
   ],
   "source": [
    "print(len(df_all))\n",
    "df_all= pd.DataFrame(set(df_all[0]))\n",
    "print(len(df_all))\n",
    "print(df_all.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  신고내용 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('속', 'Modifier'), ('보기', 'Noun')]\n",
      "[('오', 'Modifier'), ('작동', 'Noun')]\n",
      "[('경보기', 'Noun')] [('경보', 'Noun')] [('속보', 'Noun')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt \n",
    "okt = Okt()\n",
    "print(okt.pos('속보기'))  #속보기 한 단어로 인식 X   -> AAA로 임시 치환\n",
    "print(okt.pos('오작동')) # 오+작동으로 분리된 후 오가 제거되어 의미가 왜곡 -> BBB로 임시 치환\n",
    "# 문제X\n",
    "print(okt.pos('경보기'),okt.pos('경보'),okt.pos('속보')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  0\n",
      "0   의식 있음  내당홈플러스  층 꽃집 앞   여성 쓰러짐 \n",
      "1        동구시장 풀과 나무 한의원  호흡곤란 사지 마비\n",
      "2                  주간 기동순찰 및 훈련출동  \n",
      "1368100\n"
     ]
    }
   ],
   "source": [
    "df_all2 = df_all.copy()\n",
    "for i in range(len(df_all2)):\n",
    "    tmp = re.sub(r'[^가-힣+ ]',' ',df_all2.iloc[i,0]) # 한글말고 제거\n",
    "    tmp = re.sub('속보기','AAA',tmp) # 속보기 ->A로 단어 치환    \n",
    "    tmp = re.sub('오작동','BBB',tmp) # 오작동 ->B로 단어 치환    \n",
    "    df_all2.iloc[i,0] = tmp\n",
    "df_all2.iloc[702307 ,0]=re.sub('속보기','속보', df_all2.iloc[702307 ,0]) # 알수없는 이유로 치환이 안됨\n",
    "print(df_all2.head(3))\n",
    "print(len(df_all2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "속보기 단어 변경 전   : 7937\n",
      "속보기 단어 변경 후 :0\n",
      "속보기 단어 변경 전   : 9987\n",
      "오작동 단어 변경 후 :0\n",
      "AAA 단어 변경 후 :7937\n",
      "BBB 단어 변경 후 :9987\n"
     ]
    }
   ],
   "source": [
    "#속보기 단어 제거 확인\n",
    "print(f'속보기 단어 변경 전   : {df_all[0].apply(lambda x: re.search(\"속보기\", x)is not None).sum()}')\n",
    "print(f'속보기 단어 변경 후 :{df_all2[0].apply(lambda x: re.search(\"속보기\", x)is not None).sum()}')\n",
    "print(f'속보기 단어 변경 전   : {df_all[0].apply(lambda x: re.search(\"오작동\", x)is not None).sum()}')\n",
    "print(f'오작동 단어 변경 후 :{df_all2[0].apply(lambda x: re.search(\"오작동\", x)is not None).sum()}')\n",
    "print(f'AAA 단어 변경 후 :{df_all2[0].apply(lambda x: re.search(\"AAA\", x)is not None).sum()}')\n",
    "print(f'BBB 단어 변경 후 :{df_all2[0].apply(lambda x: re.search(\"BBB\", x)is not None).sum()}')\n",
    "# print(f'제거 안된 문장 :{df_all2[0][df_all2[0].apply(lambda x: re.search(\"속보기\", x)is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  문장 -> 형태소 형태로 변환\n",
    "형태소 분석(Noun, Adjective) -명사와 형용사만  \n",
    "1 글자를 배제  -의미가 거의X  \n",
    "불용어 제외  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tokenizing]  1  /  1368100   0.0  %    "
     ]
    }
   ],
   "source": [
    "\n",
    "sents = []\n",
    "for i in range(len(df_all2[0])):\n",
    "    print(\"\\r[tokenizing]  {}  /  {}   {}  %\".format(i+1, len(df_all2[0]), round( (i / len(df_all2[0])) * 100 , 1 ) ), end = '    ', flush = False)\n",
    "    pos_res = okt.pos(df_all2[0].iloc[i])\n",
    "    \n",
    "    STOP_WORDS = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "    keywords = []\n",
    "    for word, pos in pos_res:\n",
    "        if ((pos == \"Noun\")|(pos == \"Adjective\")| (pos =='Alpha'))&(len(word) >= 2)&(word not in STOP_WORDS):\n",
    "            word.replace('AAA', '속보기').replace('BBB','오작동') # 원래 단어로 되돌리기\n",
    "            keywords.append(word)\n",
    "    sents.append(' '.join(keywords))\n",
    "# print(sents[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  전처리 전후 키워드 갯수 확인\n",
    "비화재보 주요 키워드 : 경보, 속보  \n",
    "비화재보 제외 키워드 : 테스트, 오인주의, 훈련, 점검   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경보, 속보  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 [속보] 단어 수: 16048\n",
      "전처리 후 [속보] 단어 수: 16038\n"
     ]
    }
   ],
   "source": [
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '속보' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [속보] 단어 수: {df_all2[0].apply(lambda x: re.search(\"속보\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [속보] 단어 수: {len(check)}\\n')  \n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '경보' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [경보] 단어 수: {df_all2[0].apply(lambda x: re.search(\"경보\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [경보] 단어 수: {len(check)}\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트, 오인주의, 훈련, 점검   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 [오인] 단어 수: 12399\n",
      "전처리 후 [오인] 단어 수: 12188\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>상인 동 동사무소 뒷쪽   연막소독 실시 오인신고 주의        분정도 소요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>오인주의   기쁜소식 대구교회   밤  시까지 화목보일러 덴다 추가   월  일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>안심중학교 맞은편   낙엽 소각 오인 주의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>방역소독 오인주의 내일교회 주변일대   시  분까지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>오인주의   방역   경상감영공원     시  분까지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367714</th>\n",
       "      <td>농작물 소각에 대한 신고  소각행위는 지정된 장소에서 허가받아 가능하며    에서는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367723</th>\n",
       "      <td>보일러 가동  연기 발생  오인신고 주의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367851</th>\n",
       "      <td>오인주의   용산동 모닝빌라   용산네거리 동편        까지 방역소독</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367887</th>\n",
       "      <td>북구보건소 방역팀  경대교  도청교  성북교 방향 하천쪽에서 연무소독    분정도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368089</th>\n",
       "      <td>오인주의        시까지   이곡 동   꿈터공원 방역     시까지</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12399 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0\n",
       "63          상인 동 동사무소 뒷쪽   연막소독 실시 오인신고 주의        분정도 소요  \n",
       "78         오인주의   기쁜소식 대구교회   밤  시까지 화목보일러 덴다 추가   월  일...\n",
       "467                                안심중학교 맞은편   낙엽 소각 오인 주의\n",
       "507                           방역소독 오인주의 내일교회 주변일대   시  분까지\n",
       "603                          오인주의   방역   경상감영공원     시  분까지\n",
       "...                                                    ...\n",
       "1367714  농작물 소각에 대한 신고  소각행위는 지정된 장소에서 허가받아 가능하며    에서는...\n",
       "1367723                      보일러 가동  연기 발생  오인신고 주의       \n",
       "1367851         오인주의   용산동 모닝빌라   용산네거리 동편        까지 방역소독 \n",
       "1367887  북구보건소 방역팀  경대교  도청교  성북교 방향 하천쪽에서 연무소독    분정도 ...\n",
       "1368089        오인주의        시까지   이곡 동   꿈터공원 방역     시까지   \n",
       "\n",
       "[12399 rows x 1 columns]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '점검' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [점검] 단어 수: {df_all2[0].apply(lambda x: re.search(\"점검\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [점검] 단어 수: {len(check)}\\n')  \n",
    "# df_all2[df_all2[0].apply(lambda x: re.search(\"점검\", x)is not None)]\n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '훈련' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [훈련] 단어 수: {df_all2[0].apply(lambda x: re.search(\"훈련\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [훈련] 단어 수: {len(check)}\\n')  \n",
    "# df_all2[df_all2[0].apply(lambda x: re.search(\"훈련\", x)is not None)]\n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '오인' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [오인] 단어 수: {df_all2[0].apply(lambda x: re.search(\"오인\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [오인] 단어 수: {len(check)}\\n')  \n",
    "# df_all2[df_all2[0].apply(lambda x: re.search(\"오인\", x)is not None)]\n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '테스트' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [테스트] 단어 수: {df_all2[0].apply(lambda x: re.search(\"테스트\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [테스트] 단어 수: {len(check)}\\n')  \n",
    "# df_all2[df_all2[0].apply(lambda x: re.search(\"테스트\", x)is not None)]\n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if 'A' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [A] 단어 수: {df_all2[0].apply(lambda x: re.search(\"A\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [A] 단어 수: {len(check)}\\n')  \n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if 'B' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [B] 단어 수: {df_all2[0].apply(lambda x: re.search(\"B\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [B] 단어 수: {len(check)}\\n')  \n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '속보기' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [속보기] 단어 수: {df_all2[0].apply(lambda x: re.search(\"속보기\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [속보기] 단어 수: {len(check)}\\n')  \n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '오작동' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [오작동] 단어 수: {df_all2[0].apply(lambda x: re.search(\"오작동\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [오작동] 단어 수: {len(check)}\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if 'A' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [A] 단어 수: {df_all2[0].apply(lambda x: re.search(\"A\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [A] 단어 수: {len(check)}')  \n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if 'B' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [B] 단어 수: {df_all2[0].apply(lambda x: re.search(\"B\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [B] 단어 수: {len(check)}')  \n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '속보기' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [속보기] 단어 수: {df_all2[0].apply(lambda x: re.search(\"속보기\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [속보기] 단어 수: {len(check)}')  \n",
    "check = []\n",
    "for i in range(len(sents)) :\n",
    "    if '오작동' in sents[i]:\n",
    "            check.append(sents[i])\n",
    "print(f'기존 [오작동] 단어 수: {df_all2[0].apply(lambda x: re.search(\"오작동\", x)is not None).sum()}')\n",
    "print(f'전처리 후 [오작동] 단어 수: {len(check)}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 임시저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"119전처리_{start_year}-{end_year}.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(sents, fw)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"119전처리_{start_year}-{end_year}.pickle\",'rb') as fr:\n",
    "#     sents = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비화재보 /화재 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비화재보 / 전체 데이터 : 501/27432 \n",
      "비화재보 비율 : 1.83%\n"
     ]
    }
   ],
   "source": [
    "#화재보\n",
    "df_sents = pd.DataFrame(sents)\n",
    "non_fire=[]\n",
    "for i in range(len(sents)):\n",
    "    if (('경보' in df_sents.iloc[i,0])|('속보' in df_sents.iloc[i,0])) and (('점검' not in df_sents.iloc[i,0])&('훈련' not in df_sents.iloc[i,0])&('오인' not in df_sents.iloc[i,0])&('테스트' not in df_sents.iloc[i,0])):\n",
    "        non_fire.append(df_sents.iloc[i,0])\n",
    "print( f'비화재보 / 전체 데이터 : {len(non_fire)}/{len(sents)} \\n비화재보 비율 : {round((len(non_fire)/ len(sents))*100,2)}%')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[경보] 단어 수: 15571\n",
      "[속보] 단어 수: 9942\n",
      "[테스트] 단어 수: 0\n",
      "[훈련] 단어 수: 0\n",
      "[오인] 단어 수: 0\n",
      "[점검] 단어 수: 0\n"
     ]
    }
   ],
   "source": [
    "df_non_fire=pd.DataFrame(non_fire)\n",
    "print(f'[경보] 단어 수: {df_non_fire[0].apply(lambda x: re.search(\"경보\", x)is not None).sum()}')\n",
    "print(f'[속보] 단어 수: {df_non_fire[0].apply(lambda x: re.search(\"속보\", x)is not None).sum()}')\n",
    "print(f'[테스트] 단어 수: {df_non_fire[0].apply(lambda x: re.search(\"테스트\", x)is not None).sum()}')\n",
    "print(f'[훈련] 단어 수: {df_non_fire[0].apply(lambda x: re.search(\"훈련\", x)is not None).sum()}')\n",
    "print(f'[오인] 단어 수: {df_non_fire[0].apply(lambda x: re.search(\"오인\", x)is not None).sum()}')\n",
    "print(f'[점검] 단어 수: {df_non_fire[0].apply(lambda x: re.search(\"점검\", x)is not None).sum()}')\n",
    "# df_non_fire[df_non_fire[0].apply(lambda x: re.search(\"테스트\", x)is not None)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 분석\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer Vectorizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1368100, 69363)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "cv_sents=vect.fit_transform(sents)\n",
    "print(cv_sents.shape)\n",
    "# cv_data=cv_sents.toarray()\n",
    "# cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(2)  \n",
    "pca.fit(cv_sents)\n",
    "X_pca = pca.transform(cv_sents)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1368100, 69363)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_sents =vectorizer.fit_transform(sents)\n",
    "print(tfidf_sents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778936, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=0.0, analyzer='char', sublinear_tf=True, ngram_range=(1,3), max_features=10000)\n",
    "tfidf_sents =vectorizer.fit_transform(sents)\n",
    "print(tfidf_sents.shape)\n",
    "# 파라미터에 값입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec(CBOW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentences = []\n",
    "for sen in sents:\n",
    "    sentences.append(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터\n",
    "num_features = 300\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3 # 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "print(\"Training model ....\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count=min_word_count, window=context, sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "속보\n",
      ": [('설비', 0.5565919876098633), ('자동', 0.5560749769210815), ('경보', 0.5363364815711975), ('소방설비', 0.5336592197418213), ('작동', 0.4983700215816498), ('인과', 0.49686312675476074), ('소방시설', 0.4892948269844055), ('점검', 0.48302412033081055), ('경보기', 0.47331950068473816), ('테스트', 0.4692937731742859)] \n",
      "\n",
      "경보\n",
      ": [('화재경보기', 0.7432859539985657), ('보가', 0.7132909297943115), ('경보기', 0.7123016715049744), ('경종', 0.6195616722106934), ('감지기', 0.6176596879959106), ('수신기', 0.603028416633606), ('알람', 0.5819022059440613), ('번쩍', 0.5372390151023865), ('속보', 0.5363364815711975), ('발신기', 0.534061074256897)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp1 = model.wv.most_similar(\"속보\")\n",
    "tmp2= model.wv.most_similar(\"경보\")\n",
    "print(f'속보\\n: {tmp1} \\n')\n",
    "print(f'경보\\n: {tmp2} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words,model, num_features):\n",
    "    feature_vector = np.zeros((num_features), dtype=np.float32)\n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words +=1\n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(sentence, model, num_features):\n",
    "    dataset = list()\n",
    "    for s in sentence:\n",
    "        dataset.append(get_features(s, model, num_features))\n",
    "    FeatureVecs = np.stack(dataset)\n",
    "    return FeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_2544/2435305589.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  feature_vector = np.add(feature_vector, model[w])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_2544/2435305589.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vector = np.divide(feature_vector, num_words)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1368100, 300)\n"
     ]
    }
   ],
   "source": [
    "train_data_vecs = get_dataset(sentences, model, num_features)\n",
    "print(train_data_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비화재보 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfire_sentences = []\n",
    "for sen in non_fire:\n",
    "    nonfire_sentences.append(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "print(\"Training model ....\")\n",
    "model_2 = word2vec.Word2Vec(nonfire_sentences, workers=num_workers, size=num_features, min_count=min_word_count, window=context, sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "속보\n",
      ": [('국가', 0.8422040939331055), ('단대', 0.8356016874313354), ('한국', 0.8290706276893616), ('산업', 0.8263710141181946), ('요양원', 0.8251696825027466), ('자동', 0.8218286037445068), ('양병', 0.8176388740539551), ('재활', 0.8150773048400879), ('테크', 0.8133792281150818), ('주식회사', 0.8119539618492126)] \n",
      "\n",
      "경보\n",
      ": [('소리', 0.8460812568664551), ('계속', 0.8451510667800903), ('방송', 0.8240757584571838), ('일반', 0.8058801889419556), ('경로', 0.804393470287323), ('거주', 0.7888182997703552), ('인근', 0.7832477688789368), ('있다', 0.7658571004867554), ('있는', 0.7640323042869568), ('있는데', 0.7619271874427795)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp1 = model_2.wv.most_similar(\"속보\")\n",
    "tmp2= model_2.wv.most_similar(\"경보\")\n",
    "print(f'속보\\n: {tmp1} \\n')\n",
    "print(f'경보\\n: {tmp2} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>성당래미안2단지와 3단지 사이 국민은행 맞은편 건물 경보기 오작동</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0\n",
       "846  성당래미안2단지와 3단지 사이 국민은행 맞은편 건물 경보기 오작동"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1='래미안'\n",
    "word2='국민은행'\n",
    "word3=''\n",
    "\n",
    "check = df_all[df_all[0].apply(lambda x: re.search(word1, x)is not None)]\n",
    "check = check[check[0].apply(lambda x: re.search(word2, x)is not None)]\n",
    "check = check[check[0].apply(lambda x: re.search(word3, x)is not None)]\n",
    "check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
